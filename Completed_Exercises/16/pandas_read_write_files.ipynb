{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the Dark Art of Coding:\n",
    "## Introduction to Python\n",
    "pandas: reading in files\n",
    "\n",
    "<img src='../images/dark_art_logo.600px.png' width='300' style=\"float:right\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing pandas, etc\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "When using pandas, it is common to import pandas as `pd` and to simply import the factory functions: `Series` and `DataFrames`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import Series, DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Pandas is adept at reading in many, many data formats \n",
    "\n",
    "To see which ones, you can type pd.read and use **tab completion**\n",
    "\n",
    "```python\n",
    "pd.read<Press the tab key>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading from the clipboard\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's start by reading from the clipboard after we copy data from a table on a webpage.\n",
    "\n",
    "There is a sample file in the folder called:\n",
    "\n",
    "```bash\n",
    "sample_table.html\n",
    "```\n",
    "\n",
    "IF you open this file with your browser, you will see a table. Copying this table to the clipboard, allows you to read in the content to pandas directly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webdata = pd.read_clipboard()\n",
    "webdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This produces a DataFrame in memory. As with all DataFrames, you can access:\n",
    "\n",
    "* the columns\n",
    "* the rows\n",
    "* the `.attributes`\n",
    "* the `.methods()` \n",
    "\n",
    "Try these on your IPython interface:\n",
    "\n",
    "* webdata.C<press the tab key>\n",
    "* webdata.Column1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading from CSV\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will focus on `csv` and `sql` for remainder of this discussion\n",
    "Let's dive into `csv` first.\n",
    "\n",
    "To read from `csv` files, we use the `.read_csv()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In the results, notice the column headers.\n",
    "# By default, pandas will use the first\n",
    "#     row as a header row...  \n",
    "#     thus 'barry allen' shows up a the header for column 1.\n",
    "# Maybe NOT what you want..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('log_file.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if we include a list of names in the function\n",
    "# call, pandas will use those as the headers,\n",
    "# instead of the first row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "named_cols = pd.read_csv('log_file.csv',\n",
    "                         names=['name', \n",
    "                                'email', \n",
    "                                'fmip', \n",
    "                                'toip',\n",
    "                                'datetime', \n",
    "                                'lat', \n",
    "                                'long', \n",
    "                                'payload'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The .info() method shows us some details \n",
    "#     about our new DataFrame\n",
    "\n",
    "named_cols.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "It is not necessary to ingest all the lines from a file. \n",
    "\n",
    "Presuming that certain lines lack useful information... \n",
    "\n",
    "* metadata\n",
    "* header lines\n",
    "* document data, etc.\n",
    "\n",
    "In this case, let's skip rows 1, 2, 3, 7, and 9 from the csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skipped_rows = pd.read_csv('log_file.csv', \n",
    "                           names=['name', 'email', 'fmip', 'toip',\n",
    "                                  'datetime', 'lat', 'long', 'payload'],\n",
    "                           skiprows=[1, 2, 3, 7, 9])\n",
    "\n",
    "# And let's look at just one of the columns.\n",
    "skipped_rows.fmip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may receive files with alternate separators/delimiters. Pandas gives you tools to  \n",
    "deal with this situation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This file uses a 'pipe' character as the separator.\n",
    "\n",
    "piped_data = pd.read_csv('log_file_pipes.csv',\n",
    "                         names=['name', 'email', 'fmip',\n",
    "                                'toip', 'datetime', 'lat',\n",
    "                                'long', 'payload'],\n",
    "                         sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are builtin tools that let you \n",
    "#     examine subsets of the data and can\n",
    "#     help you get a sense of what the data\n",
    "#     looks like, without displaying all the \n",
    "#     data to the screen.\n",
    "\n",
    "# piped_data.tail(3)\n",
    "piped_data.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "When reading in data, `pandas` assigns a default index of `0..n`. Sometimes we want to use something different than the default indexing.\n",
    "\n",
    "We **can choose** a particular column to be used as an index.\n",
    "\n",
    "Here we chose to use the `datetime` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "date_index = pd.read_csv('log_file.csv', \n",
    "                         names=['name', 'email', 'fmip', 'toip',\n",
    "                                'datetime', 'lat', 'long', 'payload'],\n",
    "                         index_col='datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we have an index, we can select data from the DataFrame\n",
    "# based on the index. In this case, since we just made the\n",
    "# date/time our index, we can\n",
    "# easily select rows based on the date/time stamps\n",
    "\n",
    "date_index.ix['2016-02-06T21:44:56':'2016-02-06T21:49:36']\n",
    "\n",
    "# NOTE: we get a deprecation warning..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we have an index, we can select data from the DataFrame\n",
    "# based on the index. In this case, since we just made the\n",
    "# date/time our index, we can\n",
    "# easily select rows based on the date/time stamps\n",
    "\n",
    "date_index.loc['2016-02-06T21:44:56':'2016-02-06T21:49:36']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Some files have missing data or markers indicating that data is not available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_na = pd.read_csv('log_file_na.csv', \n",
    "                      names=['name', 'email', 'fmip',\n",
    "                             'toip', 'datetime', 'lat',\n",
    "                             'long', 'payload'])\n",
    "\n",
    "data_na\n",
    "# data_na.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Checking for na status and converting the value to an NaN\n",
    "# flag is a time consuming process that might not be\n",
    "# optimal when loading data.\n",
    "# You _can_ turn this process off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_na = pd.read_csv('log_file_na.csv', \n",
    "                      names=['name', 'email', 'fmip',\n",
    "                             'toip', 'datetime', 'lat', \n",
    "                             'long', 'payload'],\n",
    "                      na_filter=False)\n",
    "\n",
    "data_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You can provide a list of particular values to use\n",
    "# as na values. Some files or software will use sentinels\n",
    "# or flag values to represent a null value.\n",
    "# NOTE: in this case, pandas will combine the na_values\n",
    "# you give with the built-in na values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_na = pd.read_csv('log_file_na.csv', \n",
    "                      names=['name', 'email', 'fmip',\n",
    "                             'toip', 'datetime', 'lat',\n",
    "                             'long', 'payload'],\n",
    "                      na_values=['', '9999'])\n",
    "data_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_na = pd.read_csv('log_file_na.csv', \n",
    "                      names=['name', 'email', 'fmip',\n",
    "                             'toip', 'datetime', 'lat',\n",
    "                             'long', 'payload'],\n",
    "                         na_values=['', '9999'],\n",
    "                         keep_default_na=False)\n",
    "\n",
    "data_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_na = pd.read_csv('log_file_na.csv', \n",
    "                      names=['name', 'email', 'fmip',\n",
    "                             'toip', 'datetime', 'lat',\n",
    "                             'long', 'payload'],\n",
    "                      na_values=['', '9999'], \n",
    "                      keep_default_na=False,\n",
    "                      nrows=7)\n",
    "data_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('log_file.csv', \n",
    "                   names=['name', 'email', 'fmip', \n",
    "                          'toip', 'datetime', 'lat',\n",
    "                          'long', 'payload'],\n",
    "                   chunksize=3)\n",
    "\n",
    "for chunk in data:\n",
    "    print('\\npre-processing')\n",
    "    print('more pre-processing')\n",
    "    print('even more pre-processing')\n",
    "    print(chunk)\n",
    "    print('post processing\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If you want to convert data in one of your\n",
    "# columns, you can use a dictionary\n",
    "# to define which conversion function(s)\n",
    "# to use against which columns(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dsplitter(address):\n",
    "    userid, domain = address.split('@')\n",
    "    return userid, domain\n",
    "\n",
    "def date_only(datetime):\n",
    "    return datetime.split('T')[0]\n",
    "\n",
    "data = pd.read_csv('log_file.csv', \n",
    "                   names=['name', 'email', 'fmip',\n",
    "                          'toip', 'datetime', 'lat',\n",
    "                          'long', 'payload'],\n",
    "                   converters={'email':dsplitter,\n",
    "                               'datetime':date_only})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('log_file.csv', \n",
    "                   names=['name', 'email', 'fmip',\n",
    "                          'toip', 'datetime', 'lat',\n",
    "                          'long', 'payload'],\n",
    "                   usecols=['email', 'fmip', 'toip'])\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect('log_file.sql')\n",
    "cur = conn.cursor()\n",
    "\n",
    "df = pd.read_sql(\"SELECT * FROM superheroes\", conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_sql('''SELECT datetime, email, lat, long FROM superheroes\n",
    "                          WHERE name LIKE \"%wayne%\"''', conn)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_sql('''SELECT datetime, email, lat, long\n",
    "                     FROM superheroes\n",
    "                     WHERE name LIKE \"%wayne%\"''',\n",
    "                  conn,\n",
    "                  index_col='datetime')\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2.to_csv('class_out.csv',\n",
    "           cols=['email', 'lat', 'long', 'name'],\n",
    "           header=True, sep='|')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backups..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webdata.loc[webdata.index[[0, 2, 3]], 'Column5']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
